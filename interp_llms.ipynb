{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"1dcadf3e","cell_type":"markdown","source":"## **Interpretation in LLMs**","metadata":{}},{"id":"417849f2-f00a-4b07-bc31-6463d117c03b","cell_type":"code","source":"%%capture\n!pip install captum\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\nimport torch.nn.functional as F\nfrom captum.attr import IntegratedGradients\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:05:11.891868Z","iopub.execute_input":"2025-07-07T14:05:11.892689Z","iopub.status.idle":"2025-07-07T14:05:15.059067Z","shell.execute_reply.started":"2025-07-07T14:05:11.892658Z","shell.execute_reply":"2025-07-07T14:05:15.058334Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":23},{"id":"a2b13e91-14e1-46be-ba32-167621e992b3","cell_type":"markdown","source":"### **Attention Based Attribution**","metadata":{}},{"id":"193dcb18-2938-4eab-b63f-d1db8c17a600","cell_type":"code","source":"# Load model\nmodel_id = \"gpt2\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id, output_attentions=True)\nmodel.eval()\n\nprompt = (\n    \"On a sunny afternoon in the countryside, villagers set up colorful tents and wooden stalls for the annual harvest celebration. \"\n    \"Children chased butterflies near the fields, while parents prepared traditional dishes over open fires. \"\n    \"Music from flutes and drums filled the air as stories were shared under the shade of tall oak trees. \"\n    \"Among the crowd stood a kind-hearted little\"\n)\ntarget_token = \"girl\"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ninput_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\ntarget_id = tokenizer.convert_tokens_to_ids(target_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:55:36.352177Z","iopub.execute_input":"2025-07-07T13:55:36.352706Z","iopub.status.idle":"2025-07-07T13:55:37.329433Z","shell.execute_reply.started":"2025-07-07T13:55:36.352683Z","shell.execute_reply":"2025-07-07T13:55:37.328202Z"}},"outputs":[],"execution_count":15},{"id":"101f5dcb-7c54-4b05-ba8d-1b3998b71631","cell_type":"code","source":"with torch.no_grad():\n    outputs = model(input_ids)\n    logits = outputs.logits\n    attentions = outputs.attentions  # List of attention maps from each layer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:38:07.212244Z","iopub.execute_input":"2025-07-07T13:38:07.212707Z","iopub.status.idle":"2025-07-07T13:38:07.386717Z","shell.execute_reply.started":"2025-07-07T13:38:07.212671Z","shell.execute_reply":"2025-07-07T13:38:07.385837Z"}},"outputs":[],"execution_count":6},{"id":"791090ea-33e8-42ba-b629-87fad1afee47","cell_type":"code","source":"# Get the prediction logits\npred_logits = logits[0, -1]  # Last position (prediction after prompt)\n\n# Get top predictions\nprobs = torch.softmax(pred_logits, dim=-1)\ntopk = torch.topk(probs, k=10)\ntop_tokens = tokenizer.convert_ids_to_tokens(topk.indices.tolist())\nprint(\"Top predictions:\", top_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:38:30.842241Z","iopub.execute_input":"2025-07-07T13:38:30.842517Z","iopub.status.idle":"2025-07-07T13:38:30.848137Z","shell.execute_reply.started":"2025-07-07T13:38:30.842498Z","shell.execute_reply":"2025-07-07T13:38:30.847491Z"}},"outputs":[{"name":"stdout","text":"Top predictions: ['Ä girl', 'Ä boy', 'Ä man', 'Ä village', 'Ä woman', 'Ä child', 'Ä brother', 'Ä lady', 'Ä dog', 'Ä town']\n","output_type":"stream"}],"execution_count":7},{"id":"c990f016-133a-4a9d-b4e5-c6fedf7bc572","cell_type":"code","source":"num_layers = len(attentions)\nbatch_size, num_heads, seq_len, _ = attentions[0].shape\n\n# linear weighting -> higher layers get more weight (according to BERTology some layers speciailise in local dependencies)\nlayer_weights = torch.linspace(1.0, 2.0, steps=num_layers)\nlayer_weights /= layer_weights.sum() # normalized to 1\n\nweighted_attn = torch.zeros(seq_len)\n\nfor i, layer_attn in enumerate(attentions):\n    last_token_attn = layer_attn[0, :, -1, :] # (heads, src_len)\n    mean_attn = last_token_attn.mean(dim=0)\n    weighted_attn += layer_weights[i] * mean_attn\n\nweighted_attn /= weighted_attn.sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:42:01.433719Z","iopub.execute_input":"2025-07-07T13:42:01.434222Z","iopub.status.idle":"2025-07-07T13:42:01.442513Z","shell.execute_reply.started":"2025-07-07T13:42:01.434200Z","shell.execute_reply":"2025-07-07T13:42:01.441878Z"}},"outputs":[],"execution_count":8},{"id":"1a4103cc-0601-49ac-8186-fbf5547d90eb","cell_type":"code","source":"tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\ntoken_attn_pairs = list(zip(tokens, weighted_attn.tolist()))\ntoken_attn_sorted = sorted(token_attn_pairs, key=lambda x: x[1], reverse=True)\n\n# Print top influential tokens based on attention\nprint(\"\\nðŸ“Š Top tokens based on weighted attention to predicted token:\")\nfor token, score in token_attn_sorted:\n    token = token.replace('Ä ', '')\n    print(f\"{token:20} â†’ {score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:42:54.932461Z","iopub.execute_input":"2025-07-07T13:42:54.932739Z","iopub.status.idle":"2025-07-07T13:42:54.938888Z","shell.execute_reply.started":"2025-07-07T13:42:54.932720Z","shell.execute_reply":"2025-07-07T13:42:54.938331Z"}},"outputs":[{"name":"stdout","text":"\nðŸ“Š Top tokens based on weighted attention to predicted token:\nIn                   â†’ 0.5264\nhearted              â†’ 0.0710\nA                    â†’ 0.0584\nlittle               â†’ 0.0546\n.                    â†’ 0.0431\nkind                 â†’ 0.0396\n-                    â†’ 0.0170\nChildren             â†’ 0.0166\n.                    â†’ 0.0151\nvillage              â†’ 0.0119\nfamilies             â†’ 0.0114\nlaughter             â†’ 0.0092\nfestival             â†’ 0.0091\nthe                  â†’ 0.0087\nand                  â†’ 0.0086\nfaces                â†’ 0.0079\nran                  â†’ 0.0072\nfilled               â†’ 0.0072\npainted              â†’ 0.0069\n,                    â†’ 0.0066\nwith                 â†’ 0.0064\nair                  â†’ 0.0063\naround               â†’ 0.0055\ngathered             â†’ 0.0050\nannual               â†’ 0.0049\nfor                  â†’ 0.0044\nthe                  â†’ 0.0044\nspring               â†’ 0.0041\na                    â†’ 0.0039\nquiet                â†’ 0.0038\nnest                 â†’ 0.0036\nhills                â†’ 0.0034\nbetween              â†’ 0.0032\nthe                  â†’ 0.0028\nled                  â†’ 0.0018\n","output_type":"stream"}],"execution_count":10},{"id":"14a55329-6e78-46bf-8d35-a2bbd4d79a51","cell_type":"markdown","source":"### **Integrated Gradients**","metadata":{}},{"id":"72cbf73f-f964-41e6-8928-a7e9daaf9b5c","cell_type":"code","source":"# Load GPT-2\nmodel_id = \"gpt2\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\nmodel.eval()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nprompt = (\n    \"On a sunny afternoon in the countryside, villagers set up colorful tents and wooden stalls for the annual harvest celebration. \"\n    \"Children chased butterflies near the fields, while parents prepared traditional dishes over open fires. \"\n    \"Music from flutes and drums filled the air as stories were shared under the shade of tall oak trees. \"\n    \"Among the crowd stood a kind-hearted little\"\n)\n\ntarget_token = \"girl\"\ntarget_id = tokenizer.convert_tokens_to_ids(target_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:03:35.308530Z","iopub.execute_input":"2025-07-07T14:03:35.309145Z","iopub.status.idle":"2025-07-07T14:03:36.006616Z","shell.execute_reply.started":"2025-07-07T14:03:35.309124Z","shell.execute_reply":"2025-07-07T14:03:36.006080Z"}},"outputs":[],"execution_count":21},{"id":"faa50906-4c75-45b5-b78f-fdba98f1e1b3","cell_type":"code","source":"# Tokenize\ninputs = tokenizer(prompt, return_tensors=\"pt\")\ninput_ids = inputs[\"input_ids\"].to(device)  # (1, seq_len)\nattention_mask = inputs[\"attention_mask\"].to(device)\nseq_len = input_ids.shape[1]\n\n# Get embedding layer\nembedding_layer = model.transformer.wte\n\n# Forward function to return logit of target token\ndef forward_func(input_embeds):\n    fake_attention_mask = torch.ones(input_embeds.shape[:2], dtype=torch.long).to(device)\n    outputs = model(inputs_embeds=input_embeds, attention_mask=fake_attention_mask)\n    logits = outputs.logits  # shape: (1, seq_len, vocab_size)\n    return logits[:, -1, target_id]  # return only logit for target\n\n# Create baseline (zero embedding)\nbaseline = torch.zeros_like(embedding_layer(input_ids))\n\n# Get embeddings from input tokens\ninput_embed = embedding_layer(input_ids).detach()\ninput_embed.requires_grad = True\n\n# Run Integrated Gradients\nig = IntegratedGradients(forward_func)\nattributions, delta = ig.attribute(\n    inputs=input_embed,\n    baselines=baseline,\n    return_convergence_delta=True\n)\n\n# Aggregate attribution scores across embedding dimensions\nattribution_scores = attributions.sum(dim=-1).squeeze(0)  # (seq_len,)\n\n# Decode input tokens\ntokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze(0))\n\n# Pair tokens and attribution scores\ntoken_attr_pairs = list(zip(tokens, attribution_scores.tolist()))\ntoken_attr_pairs_sorted = sorted(token_attr_pairs, key=lambda x: abs(x[1]), reverse=True)\n\nprint(\"\\nðŸ“Š Token Influence on Predicting:\", target_token)\nfor token, score in token_attr_pairs_sorted:\n    token = token.replace(\"Ä \", \"\")\n    print(f\"{token:20} â†’ {score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:03:37.056019Z","iopub.execute_input":"2025-07-07T14:03:37.056315Z","iopub.status.idle":"2025-07-07T14:03:37.433363Z","shell.execute_reply.started":"2025-07-07T14:03:37.056297Z","shell.execute_reply":"2025-07-07T14:03:37.432766Z"}},"outputs":[{"name":"stdout","text":"\nðŸ“Š Token Influence on Predicting: girl\nsunny                â†’ 24.9788\na                    â†’ 21.0395\nlittle               â†’ -9.8640\noak                  â†’ 8.1216\nOn                   â†’ -6.1214\nin                   â†’ 6.0677\nafternoon            â†’ 6.0600\nAmong                â†’ 5.6198\nMusic                â†’ -2.9468\nover                 â†’ -2.6909\ntents                â†’ -2.2920\ndrums                â†’ 2.2845\nhearted              â†’ -2.2663\ncolorful             â†’ -2.2488\nset                  â†’ -2.2285\nthe                  â†’ 2.1400\na                    â†’ -1.9853\nvillagers            â†’ -1.8188\n,                    â†’ 1.7516\nopen                 â†’ -1.6642\nshade                â†’ 1.6149\nfrom                 â†’ -1.6038\ntrees                â†’ 1.5972\nup                   â†’ -1.5608\ncrowd                â†’ -1.5132\nnear                 â†’ -1.4539\nharvest              â†’ 1.4393\ncelebration          â†’ 1.3505\nfires                â†’ -1.3296\ndishes               â†’ -1.1240\nwooden               â†’ 1.0828\nshared               â†’ 1.0751\ntraditional          â†’ -1.0692\n.                    â†’ 1.0460\nannual               â†’ -1.0293\nstories              â†’ -0.9328\nprepared             â†’ -0.8977\nwere                 â†’ -0.8308\nthe                  â†’ -0.8095\nthe                  â†’ -0.7809\nChildren             â†’ -0.7738\nchased               â†’ 0.7684\nutes                 â†’ -0.7641\nwhile                â†’ -0.7626\nfl                   â†’ -0.7408\nfor                  â†’ -0.6420\n-                    â†’ 0.6187\nunder                â†’ 0.5658\nthe                  â†’ -0.5403\n.                    â†’ 0.5267\nand                  â†’ -0.4968\nstood                â†’ -0.4740\nfilled               â†’ -0.4595\nstalls               â†’ -0.4289\nthe                  â†’ -0.4099\nand                  â†’ 0.3824\nas                   â†’ -0.3444\nparents              â†’ 0.3231\ncountryside          â†’ 0.3081\nof                   â†’ 0.2756\nthe                  â†’ 0.2235\ntall                 â†’ -0.2093\nair                  â†’ -0.1658\nbutterflies          â†’ 0.1177\n,                    â†’ -0.0739\nkind                 â†’ -0.0586\n.                    â†’ 0.0212\nfields               â†’ 0.0111\n","output_type":"stream"}],"execution_count":22},{"id":"754abe58-79ce-43a9-a65f-291787ca8eb4","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}